{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e305fb",
   "metadata": {},
   "source": [
    "# Working with mlflow and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "402ffb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "755291ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/08 11:57:51 INFO mlflow.tracking.fluent: Experiment with name 'prediction' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "#from ensurepip import version\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "#import mlflow.sklearn\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# \n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "logging.basicConfig (level = logging .WARN )\n",
    "logger= logging.getLogger (__name__ )\n",
    "\n",
    "#Get url from DVC\n",
    "import dvc.api\n",
    "\n",
    "path='data/train.csv'\n",
    "repo ='C:/Users/Ekubay/Documents/Rossmann_Pharmaceutical_sales_Prediction'\n",
    "rev = 'ver_4'\n",
    "data_url = dvc.api.get_url(path=path, repo=repo, rev=rev)\n",
    "#df = pd.read_csv(data_url)\n",
    "\n",
    "mlflow.set_experiment('prediction')\n",
    "\n",
    "def eval_metrics ( actual , pred ) :\n",
    "    rnse = np.sqrt ( mean_squared_error ( actual , pred ) )\n",
    "    mae = mean_absolute_error ( actual , pred )\n",
    "    r2 = r2_score ( actual , pred )\n",
    "    return rnse , mae , r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c39632a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 332285 to 708709\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Store                1000 non-null   int64  \n",
      " 1   DayOfWeek            1000 non-null   int64  \n",
      " 2   Open                 1000 non-null   int64  \n",
      " 3   Promo                1000 non-null   int64  \n",
      " 4   SchoolHoliday        1000 non-null   int64  \n",
      " 5   Day                  1000 non-null   int64  \n",
      " 6   WeekOfYear           1000 non-null   int64  \n",
      " 7   Month                1000 non-null   int64  \n",
      " 8   Year                 1000 non-null   int64  \n",
      " 9   StoreType            1000 non-null   int32  \n",
      " 10  Assortment           1000 non-null   int32  \n",
      " 11  CompetitionDistance  1000 non-null   float64\n",
      " 12  Promo2               1000 non-null   int64  \n",
      "dtypes: float64(1), int32(2), int64(10)\n",
      "memory usage: 101.6 KB\n"
     ]
    }
   ],
   "source": [
    "# main \n",
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "# Read the samrt ad from the remote repository\n",
    "df_train = pd.read_csv (data_url)\n",
    "#df_train = get_data('ver_4')\n",
    "# Log data params\n",
    "mlflow.log_param ( ' data_url', data_url)\n",
    "mlflow.log_param ( ' data version ' , rev )\n",
    "mlflow.log_param ( ' input_rows ' , df_train.shape [0] )\n",
    "mlflow.log_param ( ' input_cols ' , df_train.shape [ 1 ])\n",
    "\n",
    "# checking\n",
    "#print(data['response'])\n",
    "# Split the data into training and test sets . ( 0.75 , 0.25 ) split .\n",
    "columns = ['Sales','Store', 'DayOfWeek', 'Open', 'Promo',  'SchoolHoliday', 'Day', 'WeekOfYear','Month', 'Year', 'StoreType',\n",
    "              'Assortment','CompetitionDistance', 'Promo2']\n",
    "\n",
    "feature_columns = ['Store', 'DayOfWeek', 'Open', 'Promo',  'SchoolHoliday', 'Day', 'WeekOfYear','Month', 'Year', 'StoreType',\n",
    "              'Assortment','CompetitionDistance', 'Promo2']\n",
    "\n",
    "sample_size = 1000\n",
    "sampled_df = df_train[columns].sample(sample_size)\n",
    "\n",
    "#\n",
    "lb = LabelEncoder()\n",
    "train_x['StoreType'] = lb.fit_transform(train_x['StoreType'])\n",
    "train_x['Assortment'] = lb.fit_transform(train_x['Assortment'])\n",
    "\n",
    "train_x.info()\n",
    "# scaling\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# X = x_scaler.fit_transform(train_x)\n",
    "X = train_x\n",
    "Y = y_scaler.fit_transform(train_y)\n",
    "## Separet Test and train files\n",
    "train_x = sampled_df[feature_columns]\n",
    "train_y = sampled_df[['Sales']]\n",
    "train_x.head()\n",
    "\n",
    "# training\n",
    "rf_reg = RandomForestRegressor(n_estimators = 100, max_depth=25, random_state=0)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# score of the model\n",
    "score = rf_reg.score(X_test, y_test)\n",
    "#print(f\"Prediction Score of the Model is {round(score * 100, 2)}%\"\n",
    "\n",
    "#\n",
    "cols_x = pd.DataFrame (list(train_x.columns))\n",
    "cols_x.to_csv('features.csv', header = False , index = False )\n",
    "mlflow.log_artifact('features.csv')\n",
    "\n",
    "cols_y = pd.DataFrame (list(train_y.columns))\n",
    "cols_y.to_csv('targets.csv', header = False , index = False )\n",
    "mlflow.log_artifact('targets.csv')\n",
    "\n",
    "# alpha = float ( sys.argv [ 1 ] ) if len ( sys.argv ) > 1 else 0.5\n",
    "# l1_ratio = float ( sys.argv [ 2 ] ) if len ( sys.argv ) > 2 else 0.5\n",
    "# lr = ElasticNet(alpha = alpha , l1_ratio = l1_ratio , random_state = 42 )\n",
    "# lr.fit ( train_x , train_y )\n",
    "\n",
    "#Write scores to a file\n",
    "# with open(\"metrics.txt\", 'w') as outfile:\n",
    "#     outfile.write(\"an_absolute_error: %2.1f%%\\n\" % rnse)\n",
    "#     outfile.write(\"r2_score: %2.1f%%\\n\" %r2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa6d53",
   "metadata": {},
   "source": [
    "### Runing the mlflow from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193685e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deed7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f620d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
